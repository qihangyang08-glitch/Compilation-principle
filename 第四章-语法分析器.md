### <a name="toc"></a>语法分析：自上而下篇 - 知识点索引

*   [**第一讲：语法分析器的角色与挑战**](#lecture1-role-and-challenges)
    *   [1.1 语法分析器的核心任务](#1-1-parser-task)
        *   `语法分析器 (Parser)`
        *   `Token 序列`
        *   `上下文无关文法 (CFG)`
        *   `分析树 (Parse Tree)`
        *   `抽象语法树 (AST)`
        *   `语法错误 (Syntax Error)`
    *   [1.2 自上而下分析的核心思想](#1-2-top-down-idea)
        *   `自上而下 (Top-Down)`
        *   `推导 (Derivation)`
        *   `最左推导 (Leftmost Derivation)`
    *   [1.3 自上而下分析的“三大拦路虎”](#1-3-top-down-problems)
        *   `选择困境`
        *   `回溯 (Backtracking)`
        *   `左递归 (Left Recursion)`
        *   `ε-产生式 (Epsilon Production)`
    *   [1.4 知识串联](#1-4-remember)

*   [**第二讲：LL(1)文法 —— 打造“精准导航”的语法规则**](#lecture2-ll1-grammar)
    *   [2.1 目标：预测分析器](#2-1-predictive-parser)
        *   `预测分析 (Predictive Parsing)`
        *   `非回溯分析`
    *   [2.2 解决方案一：消除左递归](#2-2-eliminate-left-recursion)
        *   `直接左递归 (Immediate Left Recursion)`
        *   `间接左递归 (Indirect Left Recursion)`
        *   `消除左递归的标准公式`
    *   [2.3 解决方案二：提取左因子](#2-3-left-factoring)
        *   `公共前缀 (Common Prefix)`
        *   `提取左因子的标准公式`
    *   [2.4 预测的“水晶球”：FIRST 集与 FOLLOW 集](#2-4-first-follow-sets)
        *   `FIRST(α)`
        *   `FOLLOW(A)`
        *   `可空非终结符 (Nullable Non-terminal)`
        *   `FIRST 集的计算规则`
        *   `FOLLOW 集的计算规则`
    *   [2.5 LL(1) 文法的最终定义](#2-5-ll1-definition)
        *   `LL(1) 分析条件`
        *   `L: Left-to-right scan`
        *   `L: Leftmost derivation`
        *   `1: 1 token lookahead`

*   [**第三讲：两种主流的 LL(1) 分析器实现**](#lecture3-ll1-implementations)
    *   [3.1 方案一：递归下降分析](#3-1-recursive-descent)
        *   `核心思想：一个非终结符 → 一个函数`
        *   `构造方法`
        *   `优缺点`
    *   [3.2 方案二：表驱动的预测分析](#3-2-table-driven)
        *   `三大组件`
            *   `输入缓冲区`
            *   `分析栈 (Parsing Stack)`
            *   `预测分析表 (Parsing Table M)`
        *   `工作原理与算法`
            *   `匹配 (Match)`
            *   `推导 (Predict/Expand)`
            *   `接受 (Accept)`
            *   `报错 (Error)`
        *   [3.2.1 预测分析表的构造](#3-2-1-build-parsing-table)
            *   `构造算法`
            *   `利用 FIRST 集填充`
            *   `利用 FOLLOW 集处理 ε-产生式`
            *   `冲突 (Conflict)`

*   [**第四讲：错误处理与总结**](#lecture4-error-handling-summary)
    *   [4.1 错误恢复策略](#4-1-error-recovery)
        *   `恐慌模式 (Panic Mode)`
        *   `同步符号 (Synchronizing Tokens)`
        *   `利用 FOLLOW 集和 FIRST 集寻找同步点`
        *   `短语级别恢复 (Phrase-level Recovery)`
    *   [4.2 自上而下分析总结](#4-2-top-down-summary)
        *   `优点 (简单、直观、易于手写)`
        *   `缺点 (文法限制较多)`
        *   `展望：为何需要自下而上分析`

---

### 第一讲：语法分析器的角色与挑战 <a name="lecture1-role-and-challenges"></a>

[返回目录](#toc)

#### 1. 语法分析器的功能：从“单词”到“句子结构”<a name="1-1-parser-task"></a>

[返回目录](#toc)

想象一下，**词法分析器**刚刚完成了它的工作。它把一长串源代码字符流，切分成了一个个有意义的“单词”（**Token**）。

例如，源代码 `if (x > 0) y = 1;`
经过词法分析后，变成了这样一个 Token 序列：
`[IF]` `[LPAREN]` `[ID, "x"]` `[GT]` `[NUM, "0"]` `[RPAREN]` `[ID, "y"]` `[ASSIGN]` `[NUM, "1"]` `[SEMICOLON]`

**语法分析器 (Parser) 的核心任务是什么？**

它的任务就是接收这个 Token 序列，然后根据**语言的语法规则 (上下文无关文法)**，检查这些单词是否能构成一个**结构正确**的“句子”。

换句话说，它要回答的问题是：**“这串单词，能组成一句合法的 C 语言/Java/Python 语句吗？”**

*   **如果能**，语法分析器就会在内存中构建一个能反映其语法结构的**分析树 (Parse Tree)** 或更常用的**抽象语法树 (Abstract Syntax Tree, AST)**。这棵树就是后面阶段（语义分析、代码生成）的工作基础。
*   **如果不能**，它就会报告一个**语法错误 (Syntax Error)**，比如“`if` 后面缺少左括号”、“分号放错了位置”等等。

**所以，语法分析器是编译器的“结构工程师”或“语法警察”。**

---

#### 2. 自上而下分析：一种充满“预见性”的分析方法<a name="1-2-top-down-idea"></a>

[返回目录](#toc)

现在，我们知道了语法分析器要做什么，那么该**怎么做**呢？

**自上而下 (Top-Down)** 分析法是一种非常直观的策略。

*   **核心思想**：从文法的**开始符号 `S`** (最顶层的语法概念，比如“程序”或“语句”) 出发，尝试**推导出**我们在输入端看到的那个 Token 序列。
*   **一个比喻**：就像一个侦探，他有一个总的猜想：“这一定是一起谋杀案”（开始符号 `S`）。然后他根据规则（文法产生式）不断细化他的猜想：“如果是谋杀案，那就需要有作案动机、作案手法、凶器...” ( `S → 动机 手法 凶器` )。他一步步地将高层概念，分解成更低层的具体概念，直到最终的细节能和现场的证据（输入的 Token）完全匹配。

这个过程，实际上就是在**从根节点开始，预先构造出分析树**的过程。

---

#### 3. 自上而下分析面临的巨大挑战 (The Problems)<a name="1-3-top-down-problems"></a>

[返回目录](#toc)

这种“预言式”的分析方法听起来很美好，但在实践中，它立刻会遇到几个致命的问题，导致它变得**不确定、低效，甚至会陷入死循环**。

这就是 4.2 节的核心内容，也是我们下一讲要重点解决的问题。

**挑战一：选择的困境 (The Choice Problem)**

*   **问题描述**：当一个非终结符 `A` 有多个产生式选项时，比如 `A → α | β`，分析器在看到当前的输入 Token `t` 时，**应该选择哪个选项（`α` 还是 `β`）** 来继续推导呢？
    *   例如，对于语句 `stmt`，文法可能是 `stmt → if_stmt | for_stmt | assign_stmt`。如果当前 Token 是 `[IF]`，选择很明显。但如果文法设计得不好，选择可能就会变得模糊。
*   **原始的解决方法**：**回溯 (Backtracking)**。随便选一个（比如 `α`），然后顺着这条路走下去。如果发现后面的 Token 对不上了，就“退回来”，擦掉刚才做的所有工作，再尝试另一个选项 `β`。
*   **缺点**：极其低效！就像走迷宫，每次都走到死胡同再从头再来，这对于需要处理数百万行代码的编译器来说是不可接受的。

**挑战二：左递归的诅咒 (The Curse of Left Recursion)**

*   **问题描述**：如果文法中存在**直接左递归** (`A → Aα`) 或**间接左递归** (`A → B...`, `B → A...`)。
*   **致命后果**：自上而下的分析器会陷入**无限循环**！
    *   分析器想推导 `A`。
    *   它选择规则 `A → Aα`。
    *   为了推导新的 `A`，它又选择了规则 `A → Aα`...
    *   这个过程永远不会消耗任何输入 Token，也永远不会结束。分析器直接崩溃。

**挑战三：空产生式的麻烦 (The Trouble with ε-Productions)**

*   **问题描述**：当存在 `A → ε` 这样的规则时。
*   **后果**：
    1.  它加剧了**选择的困境**。分析器在任何时候都可以“假装”推导出了一个 `A`，但实际上什么都没匹配。
    2.  它可能与左递归结合，导致更隐蔽的无限循环。

---
### 4. 知识串联<a name="1-4-remember"></a>

[返回目录](#toc)

**第一部分：左递归与ε-产生式 —— 自上而下分析的噩梦**

让我们用一个具体的**推导过程模拟**，来直观地感受一下灾难是如何发生的。

假设我们的分析器是一个非常“实在”的程序，它的工作方式是：
> “要推导一个非终-结符 `A`，我就调用一个名为 `parse_A()` 的函数。”

#### 场景一：直接左递归的诅咒

*   **文法**: `E → E + T | T`
*   **输入**: `id + id`
*   **分析过程**:
    1.  **`main()`** 调用 **`parse_E()`**，目标是匹配 `id + id`。
    2.  **`parse_E()`** 开始工作。它看到了 `E` 的第一条规则 `E → E + T`。
    3.  **`parse_E()`** 说：“好的，为了推导出 `E`，我需要先推导出规则右边的第一个东西，也就是... **`E`**！”
    4.  于是，**`parse_E()`** 为了完成自己的任务，**再一次调用了它自己 `parse_E()`**！
    5.  新的 **`parse_E()`** 开始工作，它看到了第一条规则 `E → E + T`...
    6.  它又一次调用了 **`parse_E()`**...
    7.  ...

*   **灾难发生**：这个过程形成了一个**无限的函数递归调用** `parse_E() -> parse_E() -> parse_E() -> ...`。
*   **根本原因**：在整个无限循环中，分析器**没有消耗掉任何一个输入 Token** (`id`)。它的目光始终停留在第一个 `id` 上，但推导过程却在原地打转，永远无法前进。最终结果就是**栈溢出 (Stack Overflow)**，程序崩溃。

#### 场景二：ε-产生式的麻烦

ε-产生式本身不一定是坏事，但它会极大地增加**不确定性**，让分析器“疑神疑鬼”。

*   **文法**:
    `A → aB | C`
    `B → b | ε`
    `C → c`
*   **输入**: `ac`
*   **分析过程**:
    1.  **`main()`** 调用 **`parse_A()`**，目标是匹配 `ac`。
    2.  **`parse_A()`** 看到当前输入是 `a`。它有两个选择 `aB` 和 `C`。`C` 的开头是 `c`，对不上。所以它**选择 `A → aB`**。
    3.  它成功地**匹配**了输入中的 `a`，并消耗掉它。现在，输入剩下 `c`。
    4.  接下来，它需要推导 `B`，于是调用 **`parse_B()`**，目标是匹配 `c`。
    5.  **`parse_B()`** 开始工作。它有两个选择 `B → b` 和 `B → ε`。
        *   **选择1 (`B → b`)**: 它需要匹配 `b`，但当前输入是 `c`。**匹配失败！**
        *   **如果这是个傻瓜分析器**，它可能会认为整条路都错了，然后**回溯**到 `parse_A()`，去尝试另一条路 `A → C`。这样效率就很低。
        *   **如果这是个聪明的分析器**，它会继续尝试 `B` 的其他选项。
    6.  **`parse_B()`** 尝试 **选择2 (`B → ε`)**。
        *   这个规则的意思是“什么都不匹配，直接成功”。
        *   `parse_B()` 成功返回，**没有消耗**任何输入。
    7.  回到 **`parse_A()`**。`B` 推导成功了。`aB` 这条路走完了。
    8.  `parse_A()` 认为自己也成功了，于是返回。
    9.  回到 **`main()`**。`parse_A()` 成功了，但输入还剩下 `c` 没有被匹配！**最终分析失败。**

*   **问题所在**：ε-产生式让分析器在任何时候都可以“假装”成功，但这种成功可能导致后续的匹配走入死胡同，或者导致输入没有被完全消耗。这大大增加了**选择的复杂性**。一个好的 LL(1) 文法，必须能够通过向后看一个 Token，就明确地知道当前是否应该选择 `ε`。

---

**第二部分：关键概念梳理**

这是一张帮你理清这些概念关系的“地图”。

#### 1. 核心目标：推导 (Derivation)

*   **推导**：从文法的开始符号 `S` 出发，通过反复应用产生式规则，最终得到一个只包含终结符的字符串（句子）的过程。
*   **分析 (Parsing)**：是推导的**逆过程**。给定一个句子，试图找到一条能推导出它的路径，并在此过程中构建分析树。

#### 2. 推导过程的两种“策略”

*   **最左推导 (Leftmost Derivation)**：在推导的每一步，**总是**选择当前字符串中**最左边**的那个非终结符进行替换。
    *   **这是所有自上而下分析法（包括LL）采用的策略。**
*   **最右推导 (Rightmost Derivation)**：在推导的每一步，**总是**选择当前字符串中**最右边**的那个非终结符进行替换。
    *   **这是所有自下而上分析法（包括LR）采用的策略。**
    *   最右推导的逆过程，被称为“规范规约 (Canonical Reduction)”。

#### 3. 文法的两种“家族”

*   **上下文无关文法 (CFG / 2型)**：这是我们的大本营。它的规则是 `A → β`。
*   **正规文法 (RG / 3型)**：这是一个特殊的、受限的 CFG 家族。
    *   **右线性文法 (RLG)**：规则是 `A → aB` 或 `A → a`。
    *   **左线性文法 (LLG)**：规则是 `A → Ba` 或 `A → a`。
    *   **关系**：RLG 和 LLG 的表达能力完全等价。你做的那道题，就是证明它们之间可以相互转换。它们都只能描述正规语言，无法处理嵌套。

#### 4. 文法的一个“坏属性”：二义性 (Ambiguity)

*   **什么是二义性文法？**
    *   如果一个文法，对于**同一个句子**，存在**至少两棵不同**的分析树，那么这个文法就是二义性的。
    *   这通常意味着，对于同一个句子，存在**至少两条不同**的最左推导路径（或最右推导路径）。
*   **为什么它很坏？**
    *   因为分析树决定了代码的**含义（语义）**。两棵不同的树，可能意味着两种完全不同的计算方式。
    *   经典的例子：`E → E + E | E * E`。对于 `3 + 4 * 5`，可以构建出 `(3+4)*5` 和 `3+(4*5)` 两棵树。
*   **消除二义性**：
    *   通过**改写文法**，强制规定运算符的**优先级和结合性**。
    *   例如，引入新的非终结符 `T` 和 `F`，将文法改写为 `E -> E+T | T`, `T -> T*F | F`... 这就是我们做过的练习。

**总结关系图**

```mermaid
graph TD
    subgraph CFG_World ["上下文无关文法 (CFG) 的世界"]
        A(文法 Ambiguity) -- 消除 --> B(无二义性文法);
        subgraph Derivation [推导策略]
            LMD(最左推导) --> TopDown(自上而下分析 LL);
            RMD(最右推导) --> BottomUp(自下而上分析 LR);
        end
        subgraph RG_Family ["正规文法 (RG) 特例"]
            RLG(右线性文法) <--> LLG(左线性文法);
        end
        B --> Derivation;
    end
    CFG_World -- 包含 --> RG_Family
```

这张图告诉你：
*   我们的基础是 CFG。
*   我们要先消除它的**二义性**。
*   然后根据选择的**推导策略**（最左或最右），决定我们是走**自上而下**还是**自下而上**的分析路线。
*   而**正规文法**，只是 CFG 的一个能力较弱但特性很好的子集，主要用于词法分析。

---


### 第二讲：LL(1)文法 —— 打造“精准导航”的语法规则<a name="lecture2-ll1-grammar"></a>

[返回目录](#toc)

---

#### 2.1 我们的目标 —— 预测分析器<a name="2-1-predictive-parser"></a>

[返回目录](#toc)

在我们深入学习如何改造文法之前，我们必须先清晰地定义我们**最终想要建造的“机器”是什么样子的**。这个理想中的机器，就叫做**预测分析器 (Predictive Parser)**。

#### 1. 什么是预测分析器？

预测分析器是一种特殊的、高效的**自上而下**分析器。它“特殊”在以下几点：

*   **无回溯 (No Backtracking)**：
    *   这是它**最核心、最宝贵**的特性。
    *   当它面临选择时（比如 `A → α | β`），它**不需要**像无头苍蝇一样先试 `α`，不行再退回来试 `β`。
    *   相反，它能够“**预测**”未来，**一次性地、确定地**做出正确的选择。

*   **“预测”的依据是什么？**
    *   它的预测能力来自于一个简单的技巧：**向前看一个输入符号 (1 Token Lookahead)**。
    *   通过窥视紧跟在当前位置的**下一个** Token，它就能准确地知道接下来应该选择哪条产生式规则进行推导。

#### 2. 预测分析器的工作模型（一个简单的比喻）

想象你在一个岔路口，面前有两条路，分别通往“北京”和“上海”。

*   **一个需要回溯的笨方法**：
    1.  你不知道该走哪条，于是你猜了一条路（比如去“北京”的路）。
    2.  你开了一天车，发现路牌上写着“欢迎来到哈尔滨”，你知道走错了。
    3.  你不得不掉头，开一天车回到岔路口，再选择去“上海”的路。
    *   这就是**回溯**，它浪费了大量的时间和资源。

*   **预测分析器的方法**：
    1.  你站在岔路口，不急着开车。
    2.  你抬头看了一眼路牌。左边的路牌上画着“天安门”（`FIRST(北京之路)`），右边的路牌上画着“东方明珠”（`FIRST(上海之路)`）。
    3.  你掏出你的行程单（输入流），看到下一个目的地是“东方明珠”。
    4.  你**立刻、确定地**选择了右边的路。
    *   这就是**预测分析**。通过“向前看”路牌（`FIRST`集），你做出了一个**不可撤销的、正确的**决定。

#### 3. 为什么我们的目标是它？

1.  **高效 (Efficient)**：
    *   因为它从不走冤枉路，分析过程是**线性的**，时间复杂度与源代码的长度成正比 `O(n)`。这对于处理大型程序至关重要。
2.  **简单 (Simple)**：
    *   预测分析器的算法逻辑相对简单，无论是手写（递归下降）还是自动生成（表驱动），都易于实现和理解。
3.  **错误定位准确 (Good Error Locality)**：
    *   当它发现当前 Token 和预测的 Token 不符时，它能立即、准确地报告错误位置，并给出有用的提示（比如“此处期望一个分号，但看到了一个右括号”）。

#### 4. 我们面临的挑战

**“理想很丰满，现实很骨感。”**

这个高效的预测分析器，对它的“图纸”——也就是**文法**，提出了极高的要求。

*   **它不能容忍任何“模棱两可”的指示**。
*   如果文法有**左递归**，它的“GPS”会原地死机。
*   如果文法有**公共前缀**（未提取左因子），它站在岔路口会看到两边的路牌上都画着“收费站”，导致它无法选择。
*   如果文法设计不满足某些条件（我们后面学的 **LL(1) 条件**），它会发现某些路牌模糊不清，或者行程单上的目的地和所有路牌都不匹配。

**所以，我们接下来要学习的所有内容——消除左递归、提取左因子、计算 FIRST/FOLLOW 集、定义 LL(11) 条件——其**唯一**的、共同的目标，就是**将一个普通的、可能有问题的上下文无关文法，改造成一本能让“预测分析器”这部机器完美运行的、清晰无误的“导航手册”**。

---


#### 2.2 解决方案一：消除左递归<a name="2-2-eliminate-left-recursion"></a>

[返回目录](#toc)

左递归是自上而下分析器的天敌，我们必须彻底消灭它。

##### **情况一：直接左递归**

这是最常见、最明显的一种。

*   **形式**：`A → Aα | β`
    *   `Aα` 是**递归项** (它以 `A` 自身开头)。
    *   `β` 是**非递归项** (它不以 `A` 开头)。

*   **问题分析**：这个文法生成的语言是什么样的？
    *   它首先必须生成一个 `β`。
    *   然后，这个 `β` 后面可以跟着**零个或多个** `α`。
    *   所以，这个文法描述的语言，用正规式来类比就是 `β(α)*`。

*   **改造手术**：我们的目标，就是用**右递归**来重新表达 `β(α)*` 这个模式。
    1.  我们引入一个新的非终结符，通常叫 `A'` (读作 A-prime)。这个 `A'` 就代表了那个“可以重复零或多次的 `α` 序列”。
    2.  `A'` 如何生成 `(α)*`？用右递归：`A' → αA' | ε`。
    3.  原来的 `A` 怎么改？它现在只需要先生成一个 `β`，然后把生成 `(α)*` 的任务交给 `A'` 就行了。所以：`A → βA'`。

*   **消除直接左递归的标准公式**：
    > 对于产生式 `A → Aα₁ | Aα₂ | ... | Aαₘ | β₁ | β₂ | ... | βₙ`
    >
    > 将其改写为：
    >
    > **`A → β₁A' | β₂A' | ... | βₙA'`**
    > **`A' → α₁A' | α₂A' | ... | αₘA' | ε`**

*   **经典例子：算术表达式**
    *   **原始文法**: `E → E + T | T`
    *   **识别**: `A=E`, `α = +T`, `β = T`
    *   **套用公式**:
        *   `E → TE'`
        *   `E' → +TE' | ε`
    *   改造后的文法完全等价，且消除了左递归。

##### **情况二：间接左递归**

这是一种更隐蔽的左递归。

*   **形式**：`A → Bα | ...`，`B → Aβ | ...`
*   **问题分析**：推导 `A` 需要先推导 `B`，而推导 `B` 又需要先推导 `A`，形成了一个推导环，最终导致无限循环 `A ⇒ Bα ⇒ Aβα`。

*   **改造手术**：通过**代入法**，将间接左递归**暴露**成直接左递归，然后再用上面的公式消除。

*   **消除间接左递归的算法**：
    1.  将所有非终结符按一定顺序列出（例如 `A₁, A₂, ..., Aₙ`）。
    2.  `for i from 1 to n:`
        *   `for j from 1 to i-1:`
            *   把所有 `Aᵢ → Aⱼγ` 形式的规则，用 `Aⱼ` 的所有产生式 `Aⱼ → δ₁ | δ₂ | ...` 进行代入。
            *   代入后，`Aᵢ` 的规则就变成了 `Aᵢ → δ₁γ | δ₂γ | ...`，从而消除了对 `Aⱼ` 的依赖。
        *   **此时，`Aᵢ` 的所有规则中，如果还存在左递归，那一定是直接左递归。**
        *   使用上面的**标准公式**，消除 `Aᵢ` 的直接左递归。

*   **例子**：
    *   **原始文法**: `S → Aa | b`, `A → Sc | d`
    *   **识别**: 顺序是 S, A。
    *   **处理 S (i=1)**: `j` 循环为空，`S` 没有直接左递归。不变。
    *   **处理 A (i=2)**: `j=1`。
        *   把 `A` 的规则 `A → Sc | d` 中的 `S`，用 `S` 的规则 `S → Aa | b` 代入。
        *   `A → (Aa|b)c | d`
        *   展开得到：`A → Aac | bc | d`
        *   **看！间接左递归成功暴露成了直接左递归！**
    *   **消除 A 的直接左递归**:
        *   `A → bcA' | dA'`
        *   `A' → acA' | ε`

    *   **最终的无左递归文法是**:
        *   `S → Aa | b`
        *   `A → bcA' | dA'`
        *   `A' → acA' | ε`

---

#### 2.3 解决方案二：提取左因子<a name="2-3-left-factoring"></a>

[返回目录](#toc)

消除了左递归，我们解决了“死循环”的问题。但“选择困难”的问题依然存在。

*   **问题描述**：当一个非终结符的多个产生式选项，有**共同的前缀**时，分析器就不知道该选哪个。
    *   例如：`stmt → if expr then stmt | if expr then stmt else stmt`
    *   当分析器看到输入是 `if` 时，它无法决定是该用第一条规则还是第二条。

*   **改造手术**：把**公共的前缀（左因子）**提取出来，把不同的部分推迟到后面一个新的非终-结符里去决定。

*   **提取左因子的标准公式**：
    > 对于产生式 `A → αδ₁ | αδ₂ | ... | αδₙ | γ` (γ是不以α开头的其他选项)
    >
    > 将其改写为：
    >
    > **`A → αA' | γ`**
    > **`A' → δ₁ | δ₂ | ... | δₙ`**

*   **经典例子：if-else 语句**
    *   **原始文法**: `S → iEtS | iEtSeS` (用 `i,t,e` 代表 `if,then,else`)
    *   **识别**: 公共前缀 `α = iEtS`。不同的部分是 `ε` 和 `eS`。
    *   **套用公式**:
        *   `S → iEtSS'`
        *   `S' → eS | ε`
    *   改造后的文法，在看到 `if...then...stmt` 之后，可以通过一个新的非终结符 `S'`，来专门判断后面到底有没有 `else`。

---


#### 2.4 FIRST 集与 FOLLOW 集<a name="2-4-first-follow-sets"></a>

[返回目录](#toc)

**FIRST 集：一个产生式能“吐出”的第一个“单词”**

*   **定义**：对于任意的文法符号串 `α` (可以是单个符号，也可以是多个符号的组合)，`FIRST(α)` 是一个**终结符**的集合。这个集合包含了从 `α` **可能推导出的所有字符串**的**第一个终结符**。

*   **特殊情况**：如果 `α` 能够推导出空串 `ε`，那么 `ε` 也要加入到 `FIRST(α)` 中。

*   **直观理解**：`FIRST(A)` 就是在问：“**如果我要推导非终结符 `A`，我可能遇到的第一个实际的单词 (Token) 会是什么？**”

**如何计算 FIRST 集？**

这是一个迭代过程，直到集合不再变化为止。

1.  **对于单个终结符 `t`**:
    *   `FIRST(t) = {t}` (一个单词的开头就是它自己)。

2.  **对于单个非终结符 `X`**:
    *   遍历 `X` 的每一个产生式 `X → Y₁Y₂...Yₖ`。
    *   将 `FIRST(Y₁)` 中**除了 `ε` 之外**的所有符号，都加入 `FIRST(X)`。
    *   **如果** `FIRST(Y₁)` **包含** `ε`，那么就继续看 `FIRST(Y₂)`，把 `FIRST(Y₂)` 中除了 `ε` 的所有符号也加入 `FIRST(X)`。
    *   这个过程一直持续下去。如果 `Y₁`, `Y₂`, ..., `Yₖ` 的 FIRST 集都包含 `ε`，那么就把 `ε` 也加入 `FIRST(X)`。

3.  **对于字符串 `α = X₁X₂...Xₙ`**:
    *   计算方法与上面类似，从 `X₁` 开始，如果 `FIRST(X₁)` 含 `ε`，就合并 `FIRST(X₂)`，以此类推。

**例子** (我们消除左递归后的文法):
*   `E → TE'`
*   `E' → +TE' | ε`
*   `T → FT'`
*   `T' → *FT' | ε`
*   `F → (E) | id`

**计算结果**:
*   `FIRST(id) = {id}`
*   `FIRST('(') = {'('}`
*   `FIRST(F) = FIRST((E)) ∪ FIRST(id) = {'(', id}`
*   `FIRST(T') = FIRST(*FT') ∪ FIRST(ε) = {'*', ε}`
*   `FIRST(T) = FIRST(FT') = FIRST(F) = {'(', id}` (因为`FIRST(F)`不含`ε`)
*   `FIRST(E') = FIRST(+TE') ∪ FIRST(ε) = {'+', ε}`
*   `FIRST(E) = FIRST(TE') = FIRST(T) = {'(', id}`

---
**FOLLOW 集：一个非终结符后面能“紧跟”的“单词”**

*   **定义**：对于非终结符 `A`，`FOLLOW(A)` 是一个**终结符**的集合。这个集合包含了在推导过程中，**可能紧跟在 `A` 后面的**那些终结符。

*   **特殊情况**：如果 `A` 可能出现在某个推导句型的最末尾，那么**文件结束符 `$`** 也要加入到 `FOLLOW(A)` 中。

*   **直观理解**：`FOLLOW(A)` 就是在问：“**在我成功推导出 `A` 之后，我应该期望看到什么样的单词？**” 这个集合对于处理 `A → ε` 这种“隐形”推导至关重要。

---

### 目标：计算 FOLLOW(A)

**核心问题**: 对于一个非终结符 `A`，在任何合法的推导过程中，什么样的**终结符** `t` 可能会**紧跟在 `A` 的后面**？

**一个重要的预备概念**:
*   **可空 (Nullable)**：一个非终结符 `X` 是“可空的”，如果 `X` 能通过一步或多步推导出空串 `ε` (即 `ε ∈ FIRST(X)`)。在计算 FOLLOW 集之前，我们必须先计算出所有符号串的 FIRST 集，并确定哪些非终结符是可空的。

---

### FOLLOW 集的计算规则 

这是一个**迭代算法**。你需要反复应用以下三条规则，直到所有非终结符的 FOLLOW 集都不再增大为止。

**准备工作**：
1.  为每一个非终结符 `A`，创建一个空的集合 `FOLLOW(A)`。
2.  设 `S` 为文法的开始符号。

**三条黄金规则：**

#### 规则 1：为开始符号“播种”

> **将文件结束符 `$` 放入 `FOLLOW(S)` 中。**

*   **原因**：开始符号 `S` 代表了整个程序或句子。当整个句子成功推导完毕后，后面紧跟的就是输入的末尾，我们用 `$` 这个特殊的终结符来表示它。这是所有 FOLLOW 集计算的起点。

#### 规则 2：寻找“紧跟在后面”的终结符

> **遍历文法中的每一个产生式，寻找形如 `P → α A β` 的规则。**
>
> **然后，将 `FIRST(β)` 中所有<u>非 `ε`</u> 的符号，全部加入到 `FOLLOW(A)` 中。**

*   **α, β**：可以是任意文法符号串（终结符、非终结符、`ε`）。
*   **原因**：这个规则是最直观的。既然在产生式里，`β` 就写在 `A` 的后面，那么 `β` 能推导出的**第一个终结符**，自然就有可能紧跟在 `A` 的后面。
*   **为什么排除 `ε`**？因为 `ε` 不是一个实际的 Token，它代表“空”。如果 `β` 本身可以变为空，那么我们就需要考虑 `β` “消失”后，`A` 后面会跟什么。这就引出了下一条规则。

#### 规则 3：处理“末尾”和“可空”的情况

> **遍历文法中的每一个产生式，寻找形如 `P → α A` 或 `P → α A β` (其中 `β` 是可空的) 的规则。**
>
> **然后，将 `FOLLOW(P)` 中的所有符号，全部加入到 `FOLLOW(A)` 中。**

*   **原因**：这个规则处理的是“**传递性**”。
    *   在 `P → αA` 中，`A` 出现在产生式的最末尾。这意味着，任何能够跟在 `P` 后面的东西，现在也都能跟在 `A` 后面。
    *   在 `P → αAβ` 中，如果 `β` 有可能“消失”（变成 `ε`），那么 `A` 就会暴露出来，直接面对那些原本跟在 `P` 后面的符号。
    *   所以，在这些情况下，`P` 的“后继者”集合 `FOLLOW(P)`，也必须成为 `A` 的“后继者”集合的一部分。

---

### 实战演练：计算表达式文法的 FOLLOW 集

**文法**：
1.  `E → T E'`
2.  `E' → + T E' | ε`
3.  `T → F T'`
4.  `T' → * F T' | ε`
5.  `F → ( E ) | id`

**预计算的 FIRST 集和可空性**：
*   `FIRST(E) = FIRST(T) = FIRST(F) = { '(', id }`
*   `FIRST(E') = { '+', ε }`  =>  `E'` **是可空的**
*   `FIRST(T') = { '*', ε }`  =>  `T'` **是可空的**

**开始迭代计算 FOLLOW 集：**

**第 0 轮 (初始化)**:
*   `FOLLOW(E) = { $ }`  (根据规则1，E是开始符号)
*   `FOLLOW(E') = { }`
*   `FOLLOW(T)  = { }`
*   `FOLLOW(T') = { }`
*   `FOLLOW(F)  = { }`

**第 1 轮 (遍历所有产生式)**:

1.  `E → T E'`:
    *   `E'` 在 `T` 后面。应用**规则2**：将 `FIRST(E')` 中非 `ε` 的 `{+}` 加入 `FOLLOW(T)`。
        *   `FOLLOW(T) = { + }`
    *   `E'` 在产生式末尾，且 `E'` 是**可空的**。应用**规则3**：将 `FOLLOW(E)` 的 `{ $ }` 加入 `FOLLOW(T)`。
        *   `FOLLOW(T) = { +, $ }`
    *   `E'` 在产生式末尾。应用**规则3**：将 `FOLLOW(E)` 的 `{ $ }` 加入 `FOLLOW(E')`。
        *   `FOLLOW(E') = { $ }`

2.  `E' → + T E'`:
    *   `E'` 在 `T` 后面。应用**规则2**：`FIRST(E')` 的 `{+}` 加入 `FOLLOW(T)`。(已存在)
    *   `E'` 是可空的，将 `FOLLOW(E')` 加入 `FOLLOW(T)`。(已存在)
    *   `E'` 在末尾，将 `FOLLOW(E')` 加入 `FOLLOW(E')`。(集合不变)

3.  `T → F T'`:
    *   `T'` 在 `F` 后面。应用**规则2**：将 `FIRST(T')` 中非 `ε` 的 `{*}` 加入 `FOLLOW(F)`。
        *   `FOLLOW(F) = { * }`
    *   `T'` 是**可空的**。应用**规则3**：将 `FOLLOW(T)` 的 `{+, $}` 加入 `FOLLOW(F)`。
        *   `FOLLOW(F) = { *, +, $ }`
    *   `T'` 在末尾。应用**规则3**：将 `FOLLOW(T)` 的 `{+, $}` 加入 `FOLLOW(T')`。
        *   `FOLLOW(T') = { +, $ }`

4.  `T' → * F T'`: (类似 `E' → + T E'`)
    *   `T'` 在 `F` 后面。`FIRST(T')` 的 `{*}` 加入 `FOLLOW(F)`。(已存在)
    *   `T'` 可空，`FOLLOW(T')` 的 `{+, $}` 加入 `FOLLOW(F)`。(已存在)
    *   `T'` 在末尾，`FOLLOW(T')` 加入 `FOLLOW(T')`。(集合不变)

5.  `F → ( E )`:
    *   `)` 在 `E` 后面。应用**规则2**：将 `FIRST(')')` 的 `{)}` 加入 `FOLLOW(E)`。
        *   `FOLLOW(E) = { $, ) }`

**第 1 轮结束时的集合状态**：
*   `FOLLOW(E) = { $, ) }`
*   `FOLLOW(E') = { $ }`
*   `FOLLOW(T)  = { +, $ }`
*   `FOLLOW(T') = { +, $ }`
*   `FOLLOW(F)  = { *, +, $ }`

**第 2 轮 (再次遍历，检查是否有变化)**:

1.  `E → T E'`:
    *   `E'` 可空，将 `FOLLOW(E)` 的 `{$, )}` 加入 `FOLLOW(T)`。
        *   `FOLLOW(T)` 变为 `{ +, $, ) }` (**有变化!**)
    *   `E'` 在末尾，将 `FOLLOW(E)` 的 `{$, )}` 加入 `FOLLOW(E')`。
        *   `FOLLOW(E')` 变为 `{ $, ) }` (**有变化!**)
    *   ...
3.  `T → F T'`:
    *   `T'` 可空，将 `FOLLOW(T)` 的 `{+, $, )}` 加入 `FOLLOW(F)`。
        *   `FOLLOW(F)` 变为 `{ *, +, $, ) }` (**有变化!**)
    *   `T'` 在末尾，将 `FOLLOW(T)` 的 `{+, $, )}` 加入 `FOLLOW(T')`。
        *   `FOLLOW(T')` 变为 `{ +, $, ) }` (**有变化!**)

**第 2 轮结束时的集合状态**：
*   `FOLLOW(E) = { $, ) }`
*   `FOLLOW(E') = { $, ) }`
*   `FOLLOW(T)  = { +, $, ) }`
*   `FOLLOW(T') = { +, $, ) }`
*   `FOLLOW(F)  = { *, +, $, ) }`

**第 3 轮 (再次遍历)**:
*   你会发现，再用这三条规则去跑一遍，没有任何集合会再增添新的成员了。

**最终结果 (算法收敛)**:
*   `FOLLOW(E) = { $, ) }`
*   `FOLLOW(E') = { $, ) }`
*   `FOLLOW(T) = { +, $, ) }`
*   `FOLLOW(T') = { +, $, ) }`
*   `FOLLOW(F) = { *, +, $, ) }`


---
#### 2.5 LL(1) 文法的最终定义<a name="2-5-ll1-definition"></a>

[返回目录](#toc)

现在我们有了“水晶球” FIRST 集和 FOLLOW 集，终于可以给出一个**精确的、可操作的**判断标准了。

一个文法是 **LL(1)** 文法，**当且仅当**，对于该文法的**每一个**非终结符 `A` 的**任何两个**不同的产生式 `A → α` 和 `A → β`，都满足以下两个条件：

**条件一：不同选项的开头不能相同。**
> `FIRST(α)` 和 `FIRST(β)` 的**交集为空** (`∩ = ∅`)。
>
> **例外**：如果其中一个（比如`α`）可以推导出 `ε`，这个条件可以放宽。
>
> **直观理解**：如果两条路都可能以 `if` 开头，那么当我看到 `if` 时，我就不知道该走哪条路了。

**条件二：如果某个选项可能为空，那么它的后继也不能是其他选项的开头。**
> 如果 `FIRST(α)` 包含 `ε`，那么 `FOLLOW(A)` 和 `FIRST(β)` 的**交集必须为空** (`∩ = ∅`)。
>
> **直观理解**：假设 `A → ε | id`。如果 `A` 后面可能跟着 `id` (即 `id ∈ FOLLOW(A)`), 那么当我看到输入是 `id` 时，我到底是该用 `A → id` 去匹配它呢，还是该用 `A → ε` “悄悄溜过去”，让后面的语法结构去匹配它呢？这就产生了**二义性**。

**LL(1) 名称的含义：**
*   **第一个 L**: 从**左** (Left) 到右扫描输入。
*   **第二个 L**: 产生**最左** (Leftmost) 推导。
*   **括号里的 1**: 在做每一个决定时，只需要**向前看 1 个** Token。

---
好的，我们正式进入第三讲。

在上一讲中，我们已经完成了所有艰难的“理论准备工作”。我们学会了如何将一个普通的上下文无关文法，通过**消除左递归**和**提取左因子**，改造成一个 LL(1) 文法。我们还掌握了 **FIRST 集**和 **FOLLOW 集**这两个强大的工具，它们是判断一个文法是否为 LL(1) 的“试金石”。

现在，我们手里已经有了一本“**清晰无误的导航手册**”（LL(1)文法）。本讲的目标，就是学习如何根据这本手册，建造出**两种不同风格、但功能相同的“导航机器人”**——也就是两种主流的 LL(1) 语法分析器。

---

### 第三讲：两种主流的 LL(1) 分析器实现<a name="lecture3-ll1-implementations"></a>

[返回目录](#toc)

#### 3.1 方案一：递归下降分析 (Recursive Descent Parsing)<a name="3-1-recursive-descent"></a>

[返回目录](#toc)

这是最直观、最容易手动编写的一种语法分析器。

*   **核心思想**:
    > **为文法中的每一个<u>非终结符</u>，都编写一个对应的 C/Java/Python <u>函数</u>。**

*   **函数的功能**:
    *   函数 `A()` 的任务，就是识别并消耗掉输入流中能够由非终结符 `A` 推导出的那部分 Token 序列。
    *   在函数体内，代码的结构严格对应 `A` 的产生式规则。

*   **构造方法 (如何将文法翻译成代码)**:
    1.  **对于产生式 `A → X₁ X₂ ... Xₖ`**:
        *   函数 `A()` 的函数体就是按顺序调用 `parse_X₁()`, `parse_X₂()`, ... `parse_Xₖ()`。
        *   如果 `Xᵢ` 是一个**非终结符** `B`，那就**递归调用** `parse_B()` 函数。
        *   如果 `Xᵢ` 是一个**终结符** `t`，那就调用一个辅助函数 `match(t)`。`match(t)` 的功能是：检查当前输入 Token 是否是 `t`，如果是，就消耗掉它并向前移动指针；如果不是，就报告语法错误。

    2.  **对于产生式 `A → α | β` (选择)**:
        *   函数 `A()` 的开头需要写一个 `if-else` 或 `switch` 语句。
        *   这个判断的依据，就是**向前看一个 Token (Lookahead)**。
        *   `if (lookahead ∈ FIRST(α))`，就走 `α` 对应的代码路径。
        *   `else if (lookahead ∈ FIRST(β))`，就走 `β` 对应的代码路径。
        *   如果 `α` 可推导为 `ε`，那么当 `lookahead ∈ FOLLOW(A)` 时，就选择 `α` 对应的路径（通常是什么都不做）。

**一个具体的例子**
*   **文法** (已消除左递归):
    `E → TE'`
    `E' → +TE' | ε`
*   **翻译成的伪代码**:
    ```python
    def parse_E():
        parse_T()
        parse_E_prime()

    def parse_E_prime():
        if lookahead == '+':  # 检查 lookahead 是否在 FIRST(+TE') 中
            match('+')
            parse_T()
            parse_E_prime()
        else:
            # lookahead 应该在 FOLLOW(E') 中，这里选择 E' -> ε
            return # 什么都不做
    ```

*   **优点**:
    *   非常直观，文法结构和代码结构一一对应，容易理解和手写。
    *   容易在分析过程中嵌入语义动作（比如直接构建 AST）。
*   **缺点**:
    *   大量的函数调用可能会带来一些性能开销。
    *   文法的任何修改都可能需要修改多个函数的代码。

---

#### 3.2 方案二：表驱动的预测分析 (Table-Driven Predictive Parsing)<a name="3-2-table-driven"></a>

[返回目录](#toc)

这是一种更通用、更高效、更适合工具自动生成的分析器。它将分析的“逻辑”和“数据”完全分离开。

*   **核心思想**:
    > 使用一个**算法**（分析程序驱动器）和一个**数据结构**（预测分析表），来模拟整个推导过程，而不需要为每个非终结符写一个函数。

*   **三大核心组件**:
    1.  **输入缓冲区 (Input Buffer)**: 存放加了结束符 `$` 的 Token 序列。
    2.  **分析栈 (Parsing Stack)**: 存放文法符号的栈，用于记录我们的“待办事项”。栈底初始时有一个 `$`，然后压入开始符号 `S`。
    3.  **预测分析表 (Parsing Table `M`)**:
        *   一个二维表，`M[A, t]`。
        *   **行**: 所有的**非终结符 `A`**。
        *   **列**: 所有的**终结符 `t`** (包括 `$`）。
        *   **内容**: 表格的每一个单元 `M[A, t]` 存放的是一条**产生式规则 `A → α`**，或者是一个**错误标记**。

*   **工作原理 (循环执行)**:
    1.  设栈顶符号为 `X`，当前输入 Token 为 `t`。
    2.  **如果 `X` 是终结符 (或 `$` )**:
        *   如果 `X == t`，**匹配成功**。从栈中弹出 `X`，输入指针后移一位。
        *   如果 `X != t`，**语法错误**。
    3.  **如果 `X` 是非终结符 `A`**:
        *   查询分析表 `M[A, t]`。
        *   **如果 `M[A, t]` 是一条产生式 `A → Y₁Y₂...Yₖ`**:
            *   **推导**！从栈中弹出 `A`。
            *   将 `Yₖ, Yₖ₋₁, ..., Y₁` **逆序**压入栈中（确保 `Y₁` 在最上面）。
        *   **如果 `M[A, t]` 是一个错误标记**: **语法错误**。
    4.  重复此过程，直到栈顶和输入都是 `$` (分析成功)，或者遇到错误。

---

#### 3.2.1 预测分析表的构造 (重点！)<a name="3-2-1-build-parsing-table"></a>

[返回目录](#toc)

这个分析器的“大脑”就是这张表。如何自动地、准确地构建它？答案还是用 **FIRST 集** 和 **FOLLOW 集**。

**构造算法**：
对于文法中的**每一个**产生式 `A → α`，执行以下操作：

1.  **对于 `FIRST(α)` 中的每一个终结符 `t`**:
    *   将产生式 `A → α` 填入 `M[A, t]`。

2.  **如果 `ε` 在 `FIRST(α)` 中 (即 `α` 是可空的)**:
    *   那么，对于 `FOLLOW(A)` 中的**每一个**终结符 `b` (包括 `$`):
    *   将产生式 `A → α` (在这里 `α` 就是 `ε`) 填入 `M[A, b]`。

**构造完成的标准**:
*   如果构造完成后，表中有任何一个单元被填入了**多于一条**的产生式，那么这个文法就**不是 LL(1) 文法**，我们称之为**冲突 (Conflict)**。
*   所有空白的单元，都是错误标记。

---


    *   [3.1 方案一：递归下降分析](#)
*   [**第四讲：错误处理与总结**](#lecture4-error-handling-summary)
    *   [4.1 错误恢复策略](#4-1-error-recovery)
    *   [4.2 自上而下分析总结](#4-2-top-down-summary)

