### <a name="toc"></a>语法分析：自上而下篇 - 知识点索引

*   [**第一讲：语法分析器的角色与挑战**](#lecture1-role-and-challenges)
    *   [1.1 语法分析器的核心任务](#1-1-parser-task)
        *   `语法分析器 (Parser)`
        *   `Token 序列`
        *   `上下文无关文法 (CFG)`
        *   `分析树 (Parse Tree)`
        *   `抽象语法树 (AST)`
        *   `语法错误 (Syntax Error)`
    *   [1.2 自上而下分析的核心思想](#1-2-top-down-idea)
        *   `自上而下 (Top-Down)`
        *   `推导 (Derivation)`
        *   `最左推导 (Leftmost Derivation)`
    *   [1.3 自上而下分析的“三大拦路虎”](#1-3-top-down-problems)
        *   `选择困境`
        *   `回溯 (Backtracking)`
        *   `左递归 (Left Recursion)`
        *   `ε-产生式 (Epsilon Production)`
 *   [1.4 知识串联](#remember)

*   [**第二讲：LL(1)文法 —— 打造“精准导航”的语法规则**](#lecture2-ll1-grammar)
    *   [2.1 目标：预测分析器](#2-1-predictive-parser)
        *   `预测分析 (Predictive Parsing)`
        *   `非回溯分析`
    *   [2.2 解决方案一：消除左递归](#2-2-eliminate-left-recursion)
        *   `直接左递归 (Immediate Left Recursion)`
        *   `间接左递归 (Indirect Left Recursion)`
        *   `消除左递归的标准公式`
    *   [2.3 解决方案二：提取左因子](#2-3-left-factoring)
        *   `公共前缀 (Common Prefix)`
        *   `提取左因子的标准公式`
    *   [2.4 预测的“水晶球”：FIRST 集与 FOLLOW 集](#2-4-first-follow-sets)
        *   `FIRST(α)`
        *   `FOLLOW(A)`
        *   `可空非终结符 (Nullable Non-terminal)`
        *   `FIRST 集的计算规则`
        *   `FOLLOW 集的计算规则`
    *   [2.5 LL(1) 文法的最终定义](#2-5-ll1-definition)
        *   `LL(1) 分析条件`
        *   `L: Left-to-right scan`
        *   `L: Leftmost derivation`
        *   `1: 1 token lookahead`

*   [**第三讲：两种主流的 LL(1) 分析器实现**](#lecture3-ll1-implementations)
    *   [3.1 方案一：递归下降分析](#3-1-recursive-descent)
        *   `核心思想：一个非终结符 → 一个函数`
        *   `构造方法`
        *   `优缺点`
    *   [3.2 方案二：表驱动的预测分析](#3-2-table-driven)
        *   `三大组件`
            *   `输入缓冲区`
            *   `分析栈 (Parsing Stack)`
            *   `预测分析表 (Parsing Table M)`
        *   `工作原理与算法`
            *   `匹配 (Match)`
            *   `推导 (Predict/Expand)`
            *   `接受 (Accept)`
            *   `报错 (Error)`
        *   [3.2.1 预测分析表的构造](#3-2-1-build-parsing-table)
            *   `构造算法`
            *   `利用 FIRST 集填充`
            *   `利用 FOLLOW 集处理 ε-产生式`
            *   `冲突 (Conflict)`

*   [**第四讲：错误处理与总结**](#lecture4-error-handling-summary)
    *   [4.1 错误恢复策略](#4-1-error-recovery)
        *   `恐慌模式 (Panic Mode)`
        *   `同步符号 (Synchronizing Tokens)`
        *   `利用 FOLLOW 集和 FIRST 集寻找同步点`
        *   `短语级别恢复 (Phrase-level Recovery)`
    *   [4.2 自上而下分析总结](#4-2-top-down-summary)
        *   `优点 (简单、直观、易于手写)`
        *   `缺点 (文法限制较多)`
        *   `展望：为何需要自下而上分析`

---

### 第一讲：语法分析器的角色与挑战 <a name="lecture1-role-and-challenges"></a>

[返回目录](#toc)

#### 1. 语法分析器的功能：从“单词”到“句子结构”<a name="1-1-parser-task"></a>

[返回目录](#toc)

想象一下，**词法分析器**刚刚完成了它的工作。它把一长串源代码字符流，切分成了一个个有意义的“单词”（**Token**）。

例如，源代码 `if (x > 0) y = 1;`
经过词法分析后，变成了这样一个 Token 序列：
`[IF]` `[LPAREN]` `[ID, "x"]` `[GT]` `[NUM, "0"]` `[RPAREN]` `[ID, "y"]` `[ASSIGN]` `[NUM, "1"]` `[SEMICOLON]`

**语法分析器 (Parser) 的核心任务是什么？**

它的任务就是接收这个 Token 序列，然后根据**语言的语法规则 (上下文无关文法)**，检查这些单词是否能构成一个**结构正确**的“句子”。

换句话说，它要回答的问题是：**“这串单词，能组成一句合法的 C 语言/Java/Python 语句吗？”**

*   **如果能**，语法分析器就会在内存中构建一个能反映其语法结构的**分析树 (Parse Tree)** 或更常用的**抽象语法树 (Abstract Syntax Tree, AST)**。这棵树就是后面阶段（语义分析、代码生成）的工作基础。
*   **如果不能**，它就会报告一个**语法错误 (Syntax Error)**，比如“`if` 后面缺少左括号”、“分号放错了位置”等等。

**所以，语法分析器是编译器的“结构工程师”或“语法警察”。**

---

#### 2. 自上而下分析：一种充满“预见性”的分析方法<a name="1-2-top-down-idea"></a>

[返回目录](#toc)

现在，我们知道了语法分析器要做什么，那么该**怎么做**呢？

**自上而下 (Top-Down)** 分析法是一种非常直观的策略。

*   **核心思想**：从文法的**开始符号 `S`** (最顶层的语法概念，比如“程序”或“语句”) 出发，尝试**推导出**我们在输入端看到的那个 Token 序列。
*   **一个比喻**：就像一个侦探，他有一个总的猜想：“这一定是一起谋杀案”（开始符号 `S`）。然后他根据规则（文法产生式）不断细化他的猜想：“如果是谋杀案，那就需要有作案动机、作案手法、凶器...” ( `S → 动机 手法 凶器` )。他一步步地将高层概念，分解成更低层的具体概念，直到最终的细节能和现场的证据（输入的 Token）完全匹配。

这个过程，实际上就是在**从根节点开始，预先构造出分析树**的过程。

---

#### 3. 自上而下分析面临的巨大挑战 (The Problems)<a name="1-3-top-down-problems"></a>

[返回目录](#toc)

这种“预言式”的分析方法听起来很美好，但在实践中，它立刻会遇到几个致命的问题，导致它变得**不确定、低效，甚至会陷入死循环**。

这就是 4.2 节的核心内容，也是我们下一讲要重点解决的问题。

**挑战一：选择的困境 (The Choice Problem)**

*   **问题描述**：当一个非终结符 `A` 有多个产生式选项时，比如 `A → α | β`，分析器在看到当前的输入 Token `t` 时，**应该选择哪个选项（`α` 还是 `β`）** 来继续推导呢？
    *   例如，对于语句 `stmt`，文法可能是 `stmt → if_stmt | for_stmt | assign_stmt`。如果当前 Token 是 `[IF]`，选择很明显。但如果文法设计得不好，选择可能就会变得模糊。
*   **原始的解决方法**：**回溯 (Backtracking)**。随便选一个（比如 `α`），然后顺着这条路走下去。如果发现后面的 Token 对不上了，就“退回来”，擦掉刚才做的所有工作，再尝试另一个选项 `β`。
*   **缺点**：极其低效！就像走迷宫，每次都走到死胡同再从头再来，这对于需要处理数百万行代码的编译器来说是不可接受的。

**挑战二：左递归的诅咒 (The Curse of Left Recursion)**

*   **问题描述**：如果文法中存在**直接左递归** (`A → Aα`) 或**间接左递归** (`A → B...`, `B → A...`)。
*   **致命后果**：自上而下的分析器会陷入**无限循环**！
    *   分析器想推导 `A`。
    *   它选择规则 `A → Aα`。
    *   为了推导新的 `A`，它又选择了规则 `A → Aα`...
    *   这个过程永远不会消耗任何输入 Token，也永远不会结束。分析器直接崩溃。

**挑战三：空产生式的麻烦 (The Trouble with ε-Productions)**

*   **问题描述**：当存在 `A → ε` 这样的规则时。
*   **后果**：
    1.  它加剧了**选择的困境**。分析器在任何时候都可以“假装”推导出了一个 `A`，但实际上什么都没匹配。
    2.  它可能与左递归结合，导致更隐蔽的无限循环。

---
#### 4. 知识串联<a name="1-4-remember"></a>

[返回目录](#toc)

### 第一部分：左递归与ε-产生式 —— 自上而下分析的噩梦

让我们用一个具体的**推导过程模拟**，来直观地感受一下灾难是如何发生的。

假设我们的分析器是一个非常“实在”的程序，它的工作方式是：
> “要推导一个非终-结符 `A`，我就调用一个名为 `parse_A()` 的函数。”

#### 场景一：直接左递归的诅咒

*   **文法**: `E → E + T | T`
*   **输入**: `id + id`
*   **分析过程**:
    1.  **`main()`** 调用 **`parse_E()`**，目标是匹配 `id + id`。
    2.  **`parse_E()`** 开始工作。它看到了 `E` 的第一条规则 `E → E + T`。
    3.  **`parse_E()`** 说：“好的，为了推导出 `E`，我需要先推导出规则右边的第一个东西，也就是... **`E`**！”
    4.  于是，**`parse_E()`** 为了完成自己的任务，**再一次调用了它自己 `parse_E()`**！
    5.  新的 **`parse_E()`** 开始工作，它看到了第一条规则 `E → E + T`...
    6.  它又一次调用了 **`parse_E()`**...
    7.  ...

*   **灾难发生**：这个过程形成了一个**无限的函数递归调用** `parse_E() -> parse_E() -> parse_E() -> ...`。
*   **根本原因**：在整个无限循环中，分析器**没有消耗掉任何一个输入 Token** (`id`)。它的目光始终停留在第一个 `id` 上，但推导过程却在原地打转，永远无法前进。最终结果就是**栈溢出 (Stack Overflow)**，程序崩溃。

#### 场景二：ε-产生式的麻烦

ε-产生式本身不一定是坏事，但它会极大地增加**不确定性**，让分析器“疑神疑鬼”。

*   **文法**:
    `A → aB | C`
    `B → b | ε`
    `C → c`
*   **输入**: `ac`
*   **分析过程**:
    1.  **`main()`** 调用 **`parse_A()`**，目标是匹配 `ac`。
    2.  **`parse_A()`** 看到当前输入是 `a`。它有两个选择 `aB` 和 `C`。`C` 的开头是 `c`，对不上。所以它**选择 `A → aB`**。
    3.  它成功地**匹配**了输入中的 `a`，并消耗掉它。现在，输入剩下 `c`。
    4.  接下来，它需要推导 `B`，于是调用 **`parse_B()`**，目标是匹配 `c`。
    5.  **`parse_B()`** 开始工作。它有两个选择 `B → b` 和 `B → ε`。
        *   **选择1 (`B → b`)**: 它需要匹配 `b`，但当前输入是 `c`。**匹配失败！**
        *   **如果这是个傻瓜分析器**，它可能会认为整条路都错了，然后**回溯**到 `parse_A()`，去尝试另一条路 `A → C`。这样效率就很低。
        *   **如果这是个聪明的分析器**，它会继续尝试 `B` 的其他选项。
    6.  **`parse_B()`** 尝试 **选择2 (`B → ε`)**。
        *   这个规则的意思是“什么都不匹配，直接成功”。
        *   `parse_B()` 成功返回，**没有消耗**任何输入。
    7.  回到 **`parse_A()`**。`B` 推导成功了。`aB` 这条路走完了。
    8.  `parse_A()` 认为自己也成功了，于是返回。
    9.  回到 **`main()`**。`parse_A()` 成功了，但输入还剩下 `c` 没有被匹配！**最终分析失败。**

*   **问题所在**：ε-产生式让分析器在任何时候都可以“假装”成功，但这种成功可能导致后续的匹配走入死胡同，或者导致输入没有被完全消耗。这大大增加了**选择的复杂性**。一个好的 LL(1) 文法，必须能够通过向后看一个 Token，就明确地知道当前是否应该选择 `ε`。

---

### 第二部分：关键概念梳理

这是一张帮你理清这些概念关系的“地图”。

#### 1. 核心目标：推导 (Derivation)

*   **推导**：从文法的开始符号 `S` 出发，通过反复应用产生式规则，最终得到一个只包含终结符的字符串（句子）的过程。
*   **分析 (Parsing)**：是推导的**逆过程**。给定一个句子，试图找到一条能推导出它的路径，并在此过程中构建分析树。

#### 2. 推导过程的两种“策略”

*   **最左推导 (Leftmost Derivation)**：在推导的每一步，**总是**选择当前字符串中**最左边**的那个非终结符进行替换。
    *   **这是所有自上而下分析法（包括LL）采用的策略。**
*   **最右推导 (Rightmost Derivation)**：在推导的每一步，**总是**选择当前字符串中**最右边**的那个非终结符进行替换。
    *   **这是所有自下而上分析法（包括LR）采用的策略。**
    *   最右推导的逆过程，被称为“规范规约 (Canonical Reduction)”。

#### 3. 文法的两种“家族”

*   **上下文无关文法 (CFG / 2型)**：这是我们的大本营。它的规则是 `A → β`。
*   **正规文法 (RG / 3型)**：这是一个特殊的、受限的 CFG 家族。
    *   **右线性文法 (RLG)**：规则是 `A → aB` 或 `A → a`。
    *   **左线性文法 (LLG)**：规则是 `A → Ba` 或 `A → a`。
    *   **关系**：RLG 和 LLG 的表达能力完全等价。你做的那道题，就是证明它们之间可以相互转换。它们都只能描述正规语言，无法处理嵌套。

#### 4. 文法的一个“坏属性”：二义性 (Ambiguity)

*   **什么是二义性文法？**
    *   如果一个文法，对于**同一个句子**，存在**至少两棵不同**的分析树，那么这个文法就是二义性的。
    *   这通常意味着，对于同一个句子，存在**至少两条不同**的最左推导路径（或最右推导路径）。
*   **为什么它很坏？**
    *   因为分析树决定了代码的**含义（语义）**。两棵不同的树，可能意味着两种完全不同的计算方式。
    *   经典的例子：`E → E + E | E * E`。对于 `3 + 4 * 5`，可以构建出 `(3+4)*5` 和 `3+(4*5)` 两棵树。
*   **消除二义性**：
    *   通过**改写文法**，强制规定运算符的**优先级和结合性**。
    *   例如，引入新的非终结符 `T` 和 `F`，将文法改写为 `E -> E+T | T`, `T -> T*F | F`... 这就是我们做过的练习。

**总结关系图**

```mermaid
graph TD
    subgraph CFG_World [上下文无关文法 (CFG) 的世界]
        A(文法 Ambiguity) -- 消除 --> B(无二义性文法);
        subgraph Derivation [推导策略]
            LMD(最左推导) --> TopDown(自上而下分析 LL);
            RMD(最右推导) --> BottomUp(自下而上分析 LR);
        end
        subgraph RG_Family [正规文法 (RG) 特例]
            RLG(右线性文法) <--> LLG(左线性文法);
        end
        B --> Derivation;
    end
    CFG_World -- 包含 --> RG_Family
```

这张图告诉你：
*   我们的基础是 CFG。
*   我们要先消除它的**二义性**。
*   然后根据选择的**推导策略**（最左或最右），决定我们是走**自上而下**还是**自下而上**的分析路线。
*   而**正规文法**，只是 CFG 的一个能力较弱但特性很好的子集，主要用于词法分析。

---


### 第二讲：LL(1)文法 —— 打造“精准导航”的语法规则<a name="lecture2-ll1-grammar"></a>

[返回目录](#toc)

#### 2.1 解决方案一：消除左递归<a name="2-1-predictive-parser"></a>

[返回目录](#toc)

左递归是自上而下分析器的天敌，我们必须彻底消灭它。

##### **情况一：直接左递归**

这是最常见、最明显的一种。

*   **形式**：`A → Aα | β`
    *   `Aα` 是**递归项** (它以 `A` 自身开头)。
    *   `β` 是**非递归项** (它不以 `A` 开头)。

*   **问题分析**：这个文法生成的语言是什么样的？
    *   它首先必须生成一个 `β`。
    *   然后，这个 `β` 后面可以跟着**零个或多个** `α`。
    *   所以，这个文法描述的语言，用正规式来类比就是 `β(α)*`。

*   **改造手术**：我们的目标，就是用**右递归**来重新表达 `β(α)*` 这个模式。
    1.  我们引入一个新的非终结符，通常叫 `A'` (读作 A-prime)。这个 `A'` 就代表了那个“可以重复零或多次的 `α` 序列”。
    2.  `A'` 如何生成 `(α)*`？用右递归：`A' → αA' | ε`。
    3.  原来的 `A` 怎么改？它现在只需要先生成一个 `β`，然后把生成 `(α)*` 的任务交给 `A'` 就行了。所以：`A → βA'`。

*   **消除直接左递归的标准公式**：
    > 对于产生式 `A → Aα₁ | Aα₂ | ... | Aαₘ | β₁ | β₂ | ... | βₙ`
    >
    > 将其改写为：
    >
    > **`A → β₁A' | β₂A' | ... | βₙA'`**
    > **`A' → α₁A' | α₂A' | ... | αₘA' | ε`**

*   **经典例子：算术表达式**
    *   **原始文法**: `E → E + T | T`
    *   **识别**: `A=E`, `α = +T`, `β = T`
    *   **套用公式**:
        *   `E → TE'`
        *   `E' → +TE' | ε`
    *   改造后的文法完全等价，且消除了左递归。

##### **情况二：间接左递归**

这是一种更隐蔽的左递归。

*   **形式**：`A → Bα | ...`，`B → Aβ | ...`
*   **问题分析**：推导 `A` 需要先推导 `B`，而推导 `B` 又需要先推导 `A`，形成了一个推导环，最终导致无限循环 `A ⇒ Bα ⇒ Aβα`。

*   **改造手术**：通过**代入法**，将间接左递归**暴露**成直接左递归，然后再用上面的公式消除。

*   **消除间接左递归的算法**：
    1.  将所有非终结符按一定顺序列出（例如 `A₁, A₂, ..., Aₙ`）。
    2.  `for i from 1 to n:`
        *   `for j from 1 to i-1:`
            *   把所有 `Aᵢ → Aⱼγ` 形式的规则，用 `Aⱼ` 的所有产生式 `Aⱼ → δ₁ | δ₂ | ...` 进行代入。
            *   代入后，`Aᵢ` 的规则就变成了 `Aᵢ → δ₁γ | δ₂γ | ...`，从而消除了对 `Aⱼ` 的依赖。
        *   **此时，`Aᵢ` 的所有规则中，如果还存在左递归，那一定是直接左递归。**
        *   使用上面的**标准公式**，消除 `Aᵢ` 的直接左递归。

*   **例子**：
    *   **原始文法**: `S → Aa | b`, `A → Sc | d`
    *   **识别**: 顺序是 S, A。
    *   **处理 S (i=1)**: `j` 循环为空，`S` 没有直接左递归。不变。
    *   **处理 A (i=2)**: `j=1`。
        *   把 `A` 的规则 `A → Sc | d` 中的 `S`，用 `S` 的规则 `S → Aa | b` 代入。
        *   `A → (Aa|b)c | d`
        *   展开得到：`A → Aac | bc | d`
        *   **看！间接左递归成功暴露成了直接左递归！**
    *   **消除 A 的直接左递归**:
        *   `A → bcA' | dA'`
        *   `A' → acA' | ε`

    *   **最终的无左递归文法是**:
        *   `S → Aa | b`
        *   `A → bcA' | dA'`
        *   `A' → acA' | ε`

---

#### 2.2 解决方案二：提取左因子<a name="2-2-eliminate-left-recursion"></a>

[返回目录](#toc)

消除了左递归，我们解决了“死循环”的问题。但“选择困难”的问题依然存在。

*   **问题描述**：当一个非终结符的多个产生式选项，有**共同的前缀**时，分析器就不知道该选哪个。
    *   例如：`stmt → if expr then stmt | if expr then stmt else stmt`
    *   当分析器看到输入是 `if` 时，它无法决定是该用第一条规则还是第二条。

*   **改造手术**：把**公共的前缀（左因子）**提取出来，把不同的部分推迟到后面一个新的非终-结符里去决定。

*   **提取左因子的标准公式**：
    > 对于产生式 `A → αδ₁ | αδ₂ | ... | αδₙ | γ` (γ是不以α开头的其他选项)
    >
    > 将其改写为：
    >
    > **`A → αA' | γ`**
    > **`A' → δ₁ | δ₂ | ... | δₙ`**

*   **经典例子：if-else 语句**
    *   **原始文法**: `S → iEtS | iEtSeS` (用 `i,t,e` 代表 `if,then,else`)
    *   **识别**: 公共前缀 `α = iEtS`。不同的部分是 `ε` 和 `eS`。
    *   **套用公式**:
        *   `S → iEtSS'`
        *   `S' → eS | ε`
    *   改造后的文法，在看到 `if...then...stmt` 之后，可以通过一个新的非终结符 `S'`，来专门判断后面到底有没有 `else`。

---

    *   [2.3 解决方案二：提取左因子](#2-3-left-factoring)
    *   [2.4 预测的“水晶球”：FIRST 集与 FOLLOW 集](#2-4-first-follow-sets)`
    *   [2.5 LL(1) 文法的最终定义](#2-5-ll1-definition)
*   [**第三讲：两种主流的 LL(1) 分析器实现**](#lecture3-ll1-implementations)
    *   [3.1 方案一：递归下降分析](#3-1-recursive-descent)
    *   [3.2 方案二：表驱动的预测分析](#3-2-table-driven)
        *   [3.2.1 预测分析表的构造](#3-2-1-build-parsing-table)
*   [**第四讲：错误处理与总结**](#lecture4-error-handling-summary)
    *   [4.1 错误恢复策略](#4-1-error-recovery)
    *   [4.2 自上而下分析总结](#4-2-top-down-summary)

